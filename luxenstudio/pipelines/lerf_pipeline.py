import typing
from abc import abstractmethod, abstractproperty
from dataclasses import dataclass, field
from typing import List, Literal, Tuple, Type

import torch.distributed as dist
import torchvision
from torch.nn.parallel import DistributedDataParallel as DDP

from luxenstudio.configs import base_config as cfg
from luxenstudio.data.datamanagers.base_datamanager import (
    DataManagerConfig,
    VanillaDataManagerConfig,
)
from luxenstudio.data.datamanagers.lerf_datamanager import (
    LERFDataManager,
    LERFDataManagerConfig,
)
from luxenstudio.models.base_model import ModelConfig
from luxenstudio.models.lerf import LERFModel, LERFModelConfig
from luxenstudio.pipelines.base_pipeline import (
    Pipeline,
    VanillaPipeline,
    VanillaPipelineConfig,
)

try:
    import open_clip
except ImportError:
    assert False, "open_clip is not installed, install it with `pip install open-clip-torch`"

import torch

from luxenstudio.pipelines.lerf_encoders import (
    ImageEncoder,
    OpenCLIPNetwork,
    OpenCLIPNetworkConfig,
)


@dataclass
class LERFPipelineConfig(VanillaPipelineConfig):
    """Configuration for pipeline instantiation"""

    _target: Type = field(default_factory=lambda: LERFPipeline)
    """target class to instantiate"""
    datamanager: LERFDataManagerConfig = LERFDataManagerConfig()
    """specifies the datamanager config"""
    model: ModelConfig = LERFModelConfig()
    """specifies the model config"""
    network: OpenCLIPNetworkConfig = OpenCLIPNetworkConfig()
    """specifies the vision-language network config"""


class LERFPipeline(VanillaPipeline):
    def __init__(
        self,
        config: LERFPipelineConfig,
        device: str,
        test_mode: Literal["test", "val", "inference"] = "val",
        world_size: int = 1,
        local_rank: int = 0,
    ):
        super(VanillaPipeline, self).__init__()
        self.config = config
        self.test_mode = test_mode

        self.image_encoder: OpenCLIPNetwork = config.network.setup()

        self.datamanager: LERFDataManager = config.datamanager.setup(
            device=device,
            test_mode=test_mode,
            world_size=world_size,
            local_rank=local_rank,
            image_encoder=self.image_encoder,
        )
        self.datamanager.to(device)

        # TODO(ethan): get rid of scene_bounds from the model
        assert self.datamanager.train_dataset is not None, "Missing input dataset"

        self._model = config.model.setup(
            scene_box=self.datamanager.train_dataset.scene_box,
            num_train_data=len(self.datamanager.train_dataset),
            metadata=self.datamanager.train_dataset.metadata,
            image_encoder=self.image_encoder,
        )
        self.model.to(device)

        self.world_size = world_size
        if world_size > 1:
            self._model = typing.cast(LERFModel, DDP(self._model, device_ids=[local_rank], find_unused_parameters=True))
            dist.barrier(device_ids=[local_rank])
